<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>databricks on menziess blog</title>
    <link>https://menziess.github.io/tags/databricks/</link>
    <description>Recent content in databricks on menziess blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 16 Nov 2020 07:15:38 +0100</lastBuildDate>
    
	<atom:link href="https://menziess.github.io/tags/databricks/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Install Python Packages on Databricks</title>
      <link>https://menziess.github.io/howto/install/python-packages-on-databricks/</link>
      <pubDate>Mon, 16 Nov 2020 07:15:38 +0100</pubDate>
      
      <guid>https://menziess.github.io/howto/install/python-packages-on-databricks/</guid>
      <description>Let&amp;rsquo;s use the same basic setup as in test python code, then use our knowledge from create python packages to convert our code to a package. And finally we will install the package on our Databricks cluster.</description>
    </item>
    
    <item>
      <title>Run Databricks Notebooks from DevOps</title>
      <link>https://menziess.github.io/howto/run/databricks-notebooks-from-devops/</link>
      <pubDate>Tue, 02 Jun 2020 02:49:01 +0100</pubDate>
      
      <guid>https://menziess.github.io/howto/run/databricks-notebooks-from-devops/</guid>
      <description>Python &lt;a href=&#34;https://menziess.github.io/howto/enhance/your-databricks-workflow&#34;&gt;packages&lt;/a&gt; are easy to test in isolation. But what if packaging your code is not an option, and you do want to automatically verify that your code actually works, you could run your databricks notebook from Azure DevOps directly using the databricks-cli.</description>
    </item>
    
    <item>
      <title>Parameterize Databricks Notebooks</title>
      <link>https://menziess.github.io/howto/parameterize/databricks-notebooks/</link>
      <pubDate>Mon, 01 Jun 2020 20:49:01 +0100</pubDate>
      
      <guid>https://menziess.github.io/howto/parameterize/databricks-notebooks/</guid>
      <description>A databricks notebook that has datetime.now() in one of its cells, will most likely behave differently when it&amp;rsquo;s run again at a later point in time. For example: when you read in data from today&amp;rsquo;s partition (june 1st) using the datetime &amp;ndash; but the notebook fails halfway through &amp;ndash; you wouldn&amp;rsquo;t be able to restart the same job on june 2nd and assume that it will read from the same partition.</description>
    </item>
    
    <item>
      <title>Enhance Your Databricks Workflow</title>
      <link>https://menziess.github.io/howto/enhance/your-databricks-workflow/</link>
      <pubDate>Sun, 01 Mar 2020 07:15:38 +0100</pubDate>
      
      <guid>https://menziess.github.io/howto/enhance/your-databricks-workflow/</guid>
      <description>With databricks-connect you can connect your favorite IDE to your Databricks cluster. This means that you can now lint, test, and package the code that you want to run on Databricks more easily:</description>
    </item>
    
    <item>
      <title>Install databricks-connect</title>
      <link>https://menziess.github.io/howto/install/databricks-connect/</link>
      <pubDate>Mon, 10 Feb 2020 07:15:38 +0100</pubDate>
      
      <guid>https://menziess.github.io/howto/install/databricks-connect/</guid>
      <description>Databricks-connect allows you to connect your favorite IDE to your Databricks cluster. Install Java on your local machine. Uninstall any pyspark versions, and install databricks-connect using the regular &lt;code&gt;pip&lt;/code&gt; commands, preventing any changes to be recorded to your virtual environment (prevents mutations to &lt;code&gt;Pipfile&lt;/code&gt; and &lt;code&gt;Pipfile.lock&lt;/code&gt;).</description>
    </item>
    
    <item>
      <title>Test Code in Databricks Notebooks</title>
      <link>https://menziess.github.io/howto/test/code-in-databricks-notebooks/</link>
      <pubDate>Mon, 03 Feb 2020 20:49:01 +0100</pubDate>
      
      <guid>https://menziess.github.io/howto/test/code-in-databricks-notebooks/</guid>
      <description>Companies hire developers to write spark applications &amp;ndash; using expensive Databricks clusters &amp;ndash; transforming and delivering business-critical data to the end user. It is advised to properly test your software: &lt;a href=&#34;https://menziess.github.io/howto/enhance/your-databricks-workflow&#34;&gt;enhance your databricks workflow&lt;/a&gt;. But if there is no time to set up proper package testing, there is always the hacker way of running tests right inside of Databricks notebooks.</description>
    </item>
    
  </channel>
</rss>